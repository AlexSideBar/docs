---
title: "Interleaved Thinking"
description: "View the AI's reasoning process in real-time for better insight into responses"
---

![Alex Sidebar showing the AI's interleaved thinking in real-time.](/images/think-mode-demo.png)

## Overview

Interleaved Thinking shows the AI's reasoning in real-time as it works through your requests. Unlike a simple response, you can see the AI's internal dialogue - how it analyzes problems, considers different approaches, and even corrects itself. This transparency helps you understand exactly how the AI arrives at its solutions.

## How It Works

Interleaved thinking is always visible for supported models. As the AI processes your request, you'll see its reasoning appear in real-time, including:

- Problem analysis and understanding
- Exploration of different approaches
- Self-corrections when it identifies mistakes
- Step-by-step logical reasoning
- Consideration of edge cases and potential issues

## Supported Models

Interleaved thinking visibility varies by model:
- **Claude Sonnet 4** - Shows thinking process
- **Gemini 2.5 Flash** - Shows thinking process
- **Gemini 2.5 Pro** - Always shows extensive thinking
- **DeepSeek R1** - Always shows thinking process
- **OpenAI o4 Mini** - Shows thinking with high thinking budget

## Visual Indicators

When using a model that shows interleaved thinking:
- The thinking appears in a dedicated section
- You can watch the AI's reasoning unfold in real-time
- Thinking content is visually separated from the final response
- The AI may revise its thinking as it discovers better approaches

<Note>
Interleaved thinking is automatically shown for all supported models. There's no need to enable or toggle this feature - it's always active to provide maximum transparency.
</Note>

## Benefits

<CardGroup cols={2}>
  <Card title="Transparency" icon="eye">
    Understand how the AI analyzes your code and arrives at solutions
  </Card>
  
  <Card title="Learning" icon="graduation-cap">
    Learn problem-solving approaches by observing the AI's reasoning process
  </Card>
  
  <Card title="Debugging" icon="bug">
    Better understand why certain suggestions are made or why specific approaches are chosen
  </Card>
  
  <Card title="Complex Problems" icon="puzzle-piece">
    Particularly useful for complex refactoring or architectural decisions
  </Card>
</CardGroup>

## Example Interleaved Thinking

Here's what you might see when the AI works through a problem:

```
Thinking...
The user is asking about a memory leak in their Swift code. Let me analyze the code they've shared...

I can see they're creating a strong reference cycle between the view controller and the closure. The closure captures 'self' strongly, and the view controller holds the closure, creating a retain cycle.

Actually, wait - I need to look more carefully at this. The closure is being used in a completion handler... 

Yes, this is definitely a retain cycle. The solution would be to use [weak self] or [unowned self] in the closure to break the cycle.
```

## When It's Most Valuable

### Complex Problem Solving
Watch the AI break down multi-step problems, evaluate different solutions, and choose the best approach.

### Debugging
See how the AI systematically investigates issues, identifies root causes, and proposes fixes.

### Learning
Understand the reasoning behind suggestions and learn problem-solving patterns.

### Architecture Decisions
Observe how the AI weighs trade-offs and considers different design patterns.

## What to Expect

<Steps>
  <Step title="Real-Time Updates">
    The interleaved thinking appears as the AI works, not after it's done thinking
  </Step>
  
  <Step title="Self-Correction">
    You may see the AI identify and fix its own mistakes during the thinking process
  </Step>
  
  <Step title="Iterative Refinement">
    The AI might explore multiple approaches before settling on the best solution
  </Step>
</Steps>

## Performance Considerations

<Info>
  Models that show interleaved thinking may take slightly longer to respond as they work through problems systematically. This deeper analysis often leads to more accurate and well-reasoned solutions.
</Info>

<Tip>
  Interleaved thinking is particularly valuable for:
  - Understanding why the AI made specific suggestions
  - Learning new problem-solving approaches
  - Catching potential issues before they become problems
  - Building trust through transparency
</Tip>